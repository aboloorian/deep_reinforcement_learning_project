{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-21T15:54:54.034250Z",
     "start_time": "2024-07-21T15:54:54.030856Z"
    }
   },
   "source": "import numpy as np",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:54:54.043120Z",
     "start_time": "2024-07-21T15:54:54.036364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Environment:\n",
    "    def __init__(self, size, goal_state, rewards):\n",
    "        self.size = size\n",
    "        self.goal_state = goal_state\n",
    "        self.rewards = rewards\n",
    "        self.actions = ['up', 'down', 'left', 'right']\n",
    "\n",
    "    def get_next_state(self, state, action):\n",
    "        row, col = divmod(state, self.size[1])\n",
    "        if action == 'up':\n",
    "            row = max(row - 1, 0)\n",
    "        elif action == 'down':\n",
    "            row = min(row + 1, self.size[0] - 1)\n",
    "        elif action == 'left':\n",
    "            col = max(col - 1, 0)\n",
    "        elif action == 'right':\n",
    "            col = min(col + 1, self.size[1] - 1)\n",
    "        return row * self.size[1] + col\n",
    "\n",
    "    def get_reward(self, state):\n",
    "        return self.rewards.get(state, -1)"
   ],
   "id": "dcee2064733d6cf0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:54:54.048099Z",
     "start_time": "2024-07-21T15:54:54.044499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Parameters:\n",
    "    def __init__(self, size, goal_state, rewards,gamma):\n",
    "        self.size = size\n",
    "        self.goal_state = goal_state\n",
    "        self.rewards = rewards\n",
    "        self.gamma = gamma"
   ],
   "id": "11bec8320f0b9b87",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T15:54:54.059307Z",
     "start_time": "2024-07-21T15:54:54.050456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Agent:\n",
    "    def __init__(self, environment, parameters, gamma=1.0):\n",
    "        self.environment = environment\n",
    "        self.gamma = gamma\n",
    "        self.policy = {state: None for state in range(environment.size[0] * environment.size[1])}\n",
    "        self.state_values = np.zeros(environment.size[0] * environment.size[1])\n",
    "        self.parameters = parameters\n",
    "\n",
    "    # Value Iteration\n",
    "    def value_iteration(self, theta=1e-9, max_iterations=1000):\n",
    "        delta = float('inf')\n",
    "        iteration = 0\n",
    "        while delta > theta and iteration < max_iterations:\n",
    "            delta = 0\n",
    "            for state in range(self.environment.size[0] * self.environment.size[1]):\n",
    "                if state == self.environment.goal_state:\n",
    "                    continue\n",
    "                value = self.state_values[state]\n",
    "                best_value = float('-inf')\n",
    "                for action in self.environment.actions:\n",
    "                    next_state = self.environment.get_next_state(state, action)\n",
    "                    reward = self.environment.get_reward(next_state)\n",
    "                    next_value = reward + self.gamma * self.state_values[next_state]\n",
    "                    best_value = max(best_value, next_value)\n",
    "                self.state_values[state] = best_value\n",
    "                delta = max(delta, abs(value - self.state_values[state]))\n",
    "            iteration += 1\n",
    "\n",
    "    # Extract policy from value function\n",
    "    def extract_policy(self):\n",
    "        for state in range(self.environment.size[0] * self.environment.size[1]):\n",
    "            if state == self.environment.goal_state:\n",
    "                continue\n",
    "            best_action = None \n",
    "            best_value = float('-inf') \n",
    "            for action in self.environment.actions:\n",
    "                next_state = self.environment.get_next_state(state, action)\n",
    "                reward = self.environment.get_reward(next_state)\n",
    "                value = reward + self.gamma * self.state_values[next_state]\n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_action = action\n",
    "            if state not in self.policy:\n",
    "                self.policy[state] = best_action\n",
    "            else:\n",
    "                self.policy[state] = best_action\n",
    "\n",
    "    # Run Value Iteration and extract policy\n",
    "    def run_value_iteration(self):\n",
    "        self.value_iteration()\n",
    "        self.extract_policy()\n",
    "\n",
    "    # Find best path for goal\n",
    "    def find_best_path_for_goal(self, start_state):\n",
    "        path = []\n",
    "        current_state = start_state\n",
    "        while current_state != self.environment.goal_state:\n",
    "            path.append(current_state)\n",
    "            current_action = self.policy[current_state]\n",
    "            current_state = self.environment.get_next_state(current_state, current_action)\n",
    "        path.append(self.environment.goal_state)\n",
    "        return path"
   ],
   "id": "a6d5e4d415884fdc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T16:01:34.568135Z",
     "start_time": "2024-07-21T15:54:54.060292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param = Parameters((3, 3),8,{8: 10,3:-5},1.0)\n",
    "# Initialize the Environment\n",
    "environment = Environment(param.size, param.goal_state, param.rewards)\n",
    "# Initialize the Agent\n",
    "agent = Agent(environment,param)\n",
    "\n",
    "# Perform policy iteration\n",
    "agent.value_iteration()\n",
    "\n",
    "# Print the state values and policy\n",
    "print(\"State Values:\")\n",
    "print(agent.state_values.reshape(param.size))\n",
    "print(\"\\nPolicy:\")\n",
    "for row in range(param.size[0]):\n",
    "    for col in range(param.size[1]):\n",
    "        state = row * param.size[1] + col\n",
    "        if state == param.goal_state:\n",
    "            print(\" G \", end=\" \")\n",
    "        else:\n",
    "            print(agent.policy[state], end=\" \")\n",
    "    print()\n",
    "\n",
    " # Find and print the best path from a starting state to the goal state\n",
    "start_state = 0\n",
    "best_path = agent.find_best_path_for_goal(start_state)\n",
    "print(\"\\nBest Path from state 0 to goal:\")\n",
    "print(best_path)"
   ],
   "id": "52256a53e0f4da63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Values:\n",
      "[[ 7.  8.  9.]\n",
      " [ 8.  9. 10.]\n",
      " [ 9. 10.  0.]]\n",
      "\n",
      "Policy:\n",
      "None None None \n",
      "None None None \n",
      "None None  G  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T16:01:34.569499Z",
     "start_time": "2024-07-21T16:01:34.569377Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bce7727f8431d562",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
