{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-23T16:49:30.260271Z",
     "start_time": "2024-07-23T16:49:30.252981Z"
    }
   },
   "source": "import numpy as np",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:49:30.276879Z",
     "start_time": "2024-07-23T16:49:30.270929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Environment:\n",
    "    def __init__(self, size, goal_state, rewards):\n",
    "        self.size = size\n",
    "        self.goal_state = goal_state\n",
    "        self.rewards = rewards\n",
    "        self.actions = ['up', 'down', 'left', 'right']\n",
    "\n",
    "    def get_next_state(self, state, action):\n",
    "        row, col = divmod(state, self.size[1])\n",
    "        if action == 'up':\n",
    "            row = max(row - 1, 0)\n",
    "        elif action == 'down':\n",
    "            row = min(row + 1, self.size[0] - 1)\n",
    "        elif action == 'left':\n",
    "            col = max(col - 1, 0)\n",
    "        elif action == 'right':\n",
    "            col = min(col + 1, self.size[1] - 1)\n",
    "        return row * self.size[1] + col\n",
    "\n",
    "    def get_reward(self, state):\n",
    "        return self.rewards.get(state, -1)"
   ],
   "id": "dcee2064733d6cf0",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:49:30.287257Z",
     "start_time": "2024-07-23T16:49:30.283930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Parameters:\n",
    "    def __init__(self, size, goal_state, rewards,gamma):\n",
    "        self.size = size\n",
    "        self.goal_state = goal_state\n",
    "        self.rewards = rewards\n",
    "        self.gamma = gamma"
   ],
   "id": "11bec8320f0b9b87",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:49:30.306131Z",
     "start_time": "2024-07-23T16:49:30.297998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PolicyIteration:\n",
    "    def __init__(self, environment, gamma=1.0):\n",
    "        self.environment = environment\n",
    "        self.gamma = gamma\n",
    "        self.policy = {}\n",
    "        self.state_values = np.zeros(environment.size[0] * environment.size[1])\n",
    "        self.initialize_policy()\n",
    "\n",
    "    #Initialization policy by random values of actions\n",
    "    def initialize_policy(self):\n",
    "        for state in range(self.environment.size[0] * self.environment.size[1]):\n",
    "            self.policy[state] = np.random.choice(self.environment.actions)\n",
    "\n",
    "    # Policy Evaluation\n",
    "    def policy_evaluation(self, iterations=100):\n",
    "        for _ in range(iterations):\n",
    "            new_state_values = np.copy(self.state_values) # create immutable to keep orignal state_values\n",
    "            for state in range(self.environment.size[0] * self.environment.size[1]):\n",
    "                if state == self.environment.goal_state:#if reach goal job is done just exit\n",
    "                    continue\n",
    "                action = self.policy[state]\n",
    "                next_state = self.environment.get_next_state(state, action)\n",
    "                reward = self.environment.get_reward(next_state)\n",
    "                new_state_values[state] = reward + self.gamma * self.state_values[next_state]\n",
    "            self.state_values = new_state_values\n",
    "\n",
    "    # Policy improvement (training)\n",
    "    def policy_improvement(self):\n",
    "        policy_stable = True\n",
    "        for state in range(self.environment.size[0] * self.environment.size[1]):\n",
    "            if state == self.environment.goal_state:\n",
    "                continue\n",
    "            old_action = self.policy[state]\n",
    "            best_action = None #null\n",
    "            best_value = float('-inf') #negative infinity\n",
    "            for action in self.environment.actions:\n",
    "                next_state = self.environment.get_next_state(state, action)\n",
    "                reward = self.environment.get_reward(next_state)\n",
    "                value = reward + self.gamma * self.state_values[next_state]\n",
    "                #find max value\n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_action = action\n",
    "            self.policy[state] = best_action\n",
    "            #ensure action converge and stabilized, if during many iteration we see no change in action so it's stabilized\n",
    "            if best_action != old_action:\n",
    "                policy_stable = False\n",
    "        return policy_stable\n",
    "\n",
    "    # Policy Iteration to reach stability = evaluation+improvement\n",
    "    def policy_iteration(self):\n",
    "        is_policy_stable = False\n",
    "        while not is_policy_stable:\n",
    "            self.policy_evaluation()\n",
    "            is_policy_stable = self.policy_improvement()\n",
    "\n",
    "    def find_best_path_for_goal(self, start_state):\n",
    "        path = []\n",
    "        current_state = start_state\n",
    "        while current_state != self.environment.goal_state:\n",
    "            path.append(current_state)\n",
    "            current_action = self.policy[current_state]\n",
    "            current_state = self.environment.get_next_state(current_state, current_action)\n",
    "        path.append(self.environment.goal_state)\n",
    "        return path"
   ],
   "id": "a6d5e4d415884fdc",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:50:27.595413Z",
     "start_time": "2024-07-23T16:50:27.577532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Policy Iteration - Grid World\")\n",
    "param = Parameters((6,6),8,{8: 10,3:-5},1.0)\n",
    "# Initialize the Environment\n",
    "environment = Environment(param.size, param.goal_state, param.rewards)\n",
    "# Initialize the Agent\n",
    "agent = PolicyIteration(environment)\n",
    "\n",
    "# Perform policy iteration\n",
    "agent.policy_iteration()\n",
    "\n",
    "# Print the state values and policy\n",
    "print(\"State Values:\")\n",
    "print(agent.state_values.reshape(param.size))\n",
    "print(\"\\nPolicy:\")\n",
    "for row in range(param.size[0]):\n",
    "    for col in range(param.size[1]):\n",
    "        state = row * param.size[1] + col\n",
    "        if state == param.goal_state:\n",
    "            print(\" G \", end=\" \")\n",
    "        else:\n",
    "            print(agent.policy[state], end=\" \")\n",
    "    print()\n",
    "\n",
    " # Find and print the best path from a starting state to the goal state\n",
    "start_state = 0\n",
    "best_path = agent.find_best_path_for_goal(start_state)\n",
    "print(\"\\nBest Path from state 0 to goal:\")\n",
    "print(best_path)"
   ],
   "id": "52256a53e0f4da63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Iteration - Grid World\n",
      "State Values:\n",
      "[[ 8.  9. 10.  9.  8.  7.]\n",
      " [ 9. 10.  0. 10.  9.  8.]\n",
      " [ 8.  9. 10.  9.  8.  7.]\n",
      " [ 7.  8.  9.  8.  7.  6.]\n",
      " [ 6.  7.  8.  7.  6.  5.]\n",
      " [ 5.  6.  7.  6.  5.  4.]]\n",
      "\n",
      "Policy:\n",
      "down down down down down down \n",
      "right right  G  left left left \n",
      "up up up up up up \n",
      "up up up up up up \n",
      "up up up up up up \n",
      "up up up up up up \n",
      "\n",
      "Best Path from state 0 to goal:\n",
      "[0, 6, 7, 8]\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:49:31.531675Z",
     "start_time": "2024-07-23T16:49:30.319996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from RL_project.secret_envs_wrapper import SecretEnv0\n",
    "\n",
    "print(\"Policy Iteration - Secret Env 0\")\n",
    "# Initialize the Environment\n",
    "environment = SecretEnv0()\n",
    "# Initialize the Agent\n",
    "agent = Agent(environment)\n",
    "\n",
    "# Perform policy iteration\n",
    "agent.policy_iteration()\n",
    "\n",
    "# Print the state values and policy\n",
    "print(\"State Values:\")\n",
    "print(agent.state_values.reshape(param.size))\n",
    "print(\"\\nPolicy:\")\n",
    "for row in range(param.size[0]):\n",
    "    for col in range(param.size[1]):\n",
    "        state = row * param.size[1] + col\n",
    "        if state == param.goal_state:\n",
    "            print(\" G \", end=\" \")\n",
    "        else:\n",
    "            print(agent.policy[state], end=\" \")\n",
    "    print()\n",
    "\n",
    " # Find and print the best path from a starting state to the goal state\n",
    "start_state = 0\n",
    "best_path = agent.find_best_path_for_goal(start_state)\n",
    "print(\"\\nBest Path from state 0 to goal:\")\n",
    "print(best_path)"
   ],
   "id": "bce7727f8431d562",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Iteration - Secret Env 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SecretEnv0' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[38], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m environment \u001B[38;5;241m=\u001B[39m SecretEnv0()\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Initialize the Agent\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m agent \u001B[38;5;241m=\u001B[39m Agent(environment)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Perform policy iteration\u001B[39;00m\n\u001B[1;32m     10\u001B[0m agent\u001B[38;5;241m.\u001B[39mpolicy_iteration()\n",
      "Cell \u001B[0;32mIn[36], line 6\u001B[0m, in \u001B[0;36mAgent.__init__\u001B[0;34m(self, environment, gamma)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgamma \u001B[38;5;241m=\u001B[39m gamma\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_values \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(environment\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m environment\u001B[38;5;241m.\u001B[39msize[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitialize_policy()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'SecretEnv0' object has no attribute 'size'"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RL_project.secret_envs_wrapper import SecretEnv1\n",
    "\n",
    "print(\"Policy Iteration - Secret Env 1\")\n",
    "# Initialize the Environment\n",
    "environment = SecretEnv1()\n",
    "# Initialize the Agent\n",
    "agent = Agent(environment,param)\n",
    "\n",
    "# Perform policy iteration\n",
    "agent.policy_iteration()\n",
    "\n",
    "# Print the state values and policy\n",
    "print(\"State Values:\")\n",
    "print(agent.state_values.reshape(param.size))\n",
    "print(\"\\nPolicy:\")\n",
    "for row in range(param.size[0]):\n",
    "    for col in range(param.size[1]):\n",
    "        state = row * param.size[1] + col\n",
    "        if state == param.goal_state:\n",
    "            print(\" G \", end=\" \")\n",
    "        else:\n",
    "            print(agent.policy[state], end=\" \")\n",
    "    print()\n",
    "\n",
    " # Find and print the best path from a starting state to the goal state\n",
    "start_state = 0\n",
    "best_path = agent.find_best_path_for_goal(start_state)\n",
    "print(\"\\nBest Path from state 0 to goal:\")\n",
    "print(best_path)"
   ],
   "id": "f2cc4228e9ee83aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RL_project.secret_envs_wrapper import SecretEnv2\n",
    "\n",
    "print(\"Policy Iteration - Secret Env 2\")\n",
    "# Initialize the Environment\n",
    "environment = SecretEnv2()\n",
    "# Initialize the Agent\n",
    "agent = Agent(environment,param)\n",
    "\n",
    "# Perform policy iteration\n",
    "agent.policy_iteration()\n",
    "\n",
    "# Print the state values and policy\n",
    "print(\"State Values:\")\n",
    "print(agent.state_values.reshape(param.size))\n",
    "print(\"\\nPolicy:\")\n",
    "for row in range(param.size[0]):\n",
    "    for col in range(param.size[1]):\n",
    "        state = row * param.size[1] + col\n",
    "        if state == param.goal_state:\n",
    "            print(\" G \", end=\" \")\n",
    "        else:\n",
    "            print(agent.policy[state], end=\" \")\n",
    "    print()\n",
    "\n",
    " # Find and print the best path from a starting state to the goal state\n",
    "start_state = 0\n",
    "best_path = agent.find_best_path_for_goal(start_state)\n",
    "print(\"\\nBest Path from state 0 to goal:\")\n",
    "print(best_path)"
   ],
   "id": "31f3893d1cca89f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from RL_project.secret_envs_wrapper import SecretEnv3\n",
    "\n",
    "print(\"Policy Iteration - Secret Env 3\")\n",
    "# Initialize the Environment\n",
    "environment = SecretEnv3()\n",
    "# Initialize the Agent\n",
    "agent = Agent(environment,param)\n",
    "\n",
    "# Perform policy iteration\n",
    "agent.policy_iteration()\n",
    "\n",
    "# Print the state values and policy\n",
    "print(\"State Values:\")\n",
    "print(agent.state_values.reshape(param.size))\n",
    "print(\"\\nPolicy:\")\n",
    "for row in range(param.size[0]):\n",
    "    for col in range(param.size[1]):\n",
    "        state = row * param.size[1] + col\n",
    "        if state == param.goal_state:\n",
    "            print(\" G \", end=\" \")\n",
    "        else:\n",
    "            print(agent.policy[state], end=\" \")\n",
    "    print()\n",
    "\n",
    " # Find and print the best path from a starting state to the goal state\n",
    "start_state = 0\n",
    "best_path = agent.find_best_path_for_goal(start_state)\n",
    "print(\"\\nBest Path from state 0 to goal:\")\n",
    "print(best_path)"
   ],
   "id": "a6af2780ac9577f4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
